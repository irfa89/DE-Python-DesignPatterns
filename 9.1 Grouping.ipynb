{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "96be5fff-a758-40ae-85ff-53fbb5bdafe1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**Pattern 1** — Group by Single Key (customer_id)\n",
    "\n",
    "**Problem:** Group all transactions by customer.\n",
    "\n",
    "**Task:** Given a list of transaction rows, build a mapping customer_id → list of rows so we can later aggregate per customer (total spend, counts, etc.)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d47c5198-24f6-4208-946c-08f68adc1c04",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "rows = [\n",
    "    {\"customer_id\": 101, \"amount\": 50},\n",
    "    {\"customer_id\": 102, \"amount\": 30},\n",
    "    {\"customer_id\": 101, \"amount\": 20},\n",
    "    {\"customer_id\": 103, \"amount\": 70},\n",
    "    {\"customer_id\": 102, \"amount\": 10},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4be97efb-2476-4aad-8be1-2fe09dab5ef7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Idea (Group by a single key)\n",
    "\n",
    "Walk the list once:\n",
    "- Use a dict: key = customer_id, value = list of all that customer's rows.\n",
    "- For each row, compute key = row['customer_id'] and append row to groups[key].\n",
    "\n",
    "This mirrors SQL: SELECT * FROM rows GROUP BY customer_id;\n",
    "\"\"\"\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "def group_by_customer(rows):\n",
    "    groups = defaultdict(list)\n",
    "    for row in rows:\n",
    "        cid = row[\"customer_id\"]\n",
    "        groups[cid].append(row)\n",
    "    return groups\n",
    "\n",
    "groups = group_by_customer(rows)\n",
    "# Example: groups[101] → list of all rows for customer 101"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0a4c70f3-2aad-4e5c-99df-17176bd0afc4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Why this is “Group by Single Key”\n",
    "One dictionary key, one dimension (customer). Very common for “per-user”, “per-account”, “per-session” logic.\n",
    "\n",
    "**Time & Space Complexity**\n",
    "\n",
    "Time: one pass over rows → O(n)\n",
    "\n",
    "Space: store all rows in the dict → O(n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "fa89fac3-aac0-415a-871b-933c3484441f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**Pattern 2** — Group by Composite Key (customer_id, order_date)\n",
    "\n",
    "**Problem:** Group orders by (customer_id, order_date) to match fact grain or compute per-day metrics per customer.\n",
    "\n",
    "**Task:** Given order lines, build mapping (customer_id, order_date) → list of rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c8fa9e87-1da3-4feb-aa36-9cfad2f2aeb9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "rows = [\n",
    "    {\"customer_id\": 101, \"order_date\": \"2025-11-20\", \"order_id\": 1, \"amount\": 50},\n",
    "    {\"customer_id\": 101, \"order_date\": \"2025-11-20\", \"order_id\": 2, \"amount\": 30},\n",
    "    {\"customer_id\": 101, \"order_date\": \"2025-11-21\", \"order_id\": 3, \"amount\": 40},\n",
    "    {\"customer_id\": 102, \"order_date\": \"2025-11-20\", \"order_id\": 4, \"amount\": 25},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d90cccc6-25a4-4bda-b522-560ae6a10fe5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Idea (Composite key = tuple)\n",
    "\n",
    "Fact tables often use multiple columns as grain (customer_id + order_date).\n",
    "We mimic that in Python by using a tuple key:\n",
    "\n",
    "key = (row['customer_id'], row['order_date'])\n",
    "\n",
    "All rows with the same key land in the same bucket.\n",
    "\"\"\"\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "def group_by_customer_date(rows):\n",
    "    groups = defaultdict(list)\n",
    "    for row in rows:\n",
    "        key = (row[\"customer_id\"], row[\"order_date\"])\n",
    "        groups[key].append(row)\n",
    "    return groups\n",
    "\n",
    "groups = group_by_customer_date(rows)\n",
    "# Example: groups[(101, \"2025-11-20\")] → 2 rows (order_id 1, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3ef4dc44-45c0-4352-af0f-0a2b6a6fddfa",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Why this is “Group by Composite Key”\n",
    "The grouping dimension is the combination of fields. This matches SQL GROUP BY customer_id, order_date and is very common in DE interviews.\n",
    "\n",
    "**Time & Space Complexity**\n",
    "\n",
    "Time: one pass → O(n)\n",
    "\n",
    "Space: store all rows in dict buckets → O(n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b118401a-cf7d-4fbc-a962-85fdcfdab724",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**Pattern 3** — Group by Category → List Extraction\n",
    "\n",
    "**Problem:** For each product category, collect the list of SKUs in that category.\n",
    "\n",
    "**Task:** Build category → [sku1, sku2, ...] for fast lookups or downstream export."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "47528d5e-5beb-4db6-8b43-9886df58967d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "items = [\n",
    "    {\"sku\": \"A100\", \"cat\": \"electronics\"},\n",
    "    {\"sku\": \"A101\", \"cat\": \"electronics\"},\n",
    "    {\"sku\": \"B200\", \"cat\": \"books\"},\n",
    "    {\"sku\": \"B201\", \"cat\": \"books\"},\n",
    "    {\"sku\": \"H300\", \"cat\": \"home\"},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d920a6f3-9704-480e-b4a6-18bd08f775a5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Idea (Group by key, store only selected field)\n",
    "\n",
    "We don't always need entire rows in each group.\n",
    "Here:\n",
    "- Group key = item[\"cat\"]\n",
    "- Stored value = item[\"sku\"]\n",
    "\n",
    "So each category maps to just the SKUs (lighter than full rows).\n",
    "\"\"\"\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "def skus_by_category(items):\n",
    "    items_by_cat = defaultdict(list)\n",
    "    for item in items:\n",
    "        cat = item[\"cat\"]\n",
    "        items_by_cat[cat].append(item[\"sku\"])\n",
    "    return items_by_cat\n",
    "\n",
    "items_by_cat = skus_by_category(items)\n",
    "# Example: items_by_cat[\"books\"] → [\"B200\", \"B201\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c5280dc1-816f-490a-bc37-241fbf8c3e60",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Why this is “Group → List Extraction”\n",
    "You group by one column but only keep a specific field (SKU) in the group. Used a lot for building id-lists, email-lists, etc.\n",
    "\n",
    "**Time & Space Complexity**\n",
    "\n",
    "Time: single pass over items → O(n)\n",
    "\n",
    "Space: store every SKU in some list → O(n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b823f14a-62fc-47dd-ae9e-265c3fbacf86",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**Pattern 4** — Group by Hour (Time Bucketing)\n",
    "\n",
    "**Problem:** Group logs into hourly buckets to compute per-hour metrics.\n",
    "\n",
    "**Task:** Given logs with timestamp strings, group by hour yyyy-mm-dd HH."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7b829537-19e4-49de-bd76-8244e5b5cbbb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "logs = [\n",
    "    {\"ts\": \"2025-11-20 10:01:05\", \"status\": 200},\n",
    "    {\"ts\": \"2025-11-20 10:15:30\", \"status\": 500},\n",
    "    {\"ts\": \"2025-11-20 11:00:00\", \"status\": 200},\n",
    "    {\"ts\": \"2025-11-20 11:45:10\", \"status\": 404},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "540da79c-91c6-4e21-baa9-2b44b5fa58f8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Idea (Truncate timestamp to bucket key)\n",
    "\n",
    "For many real-time / monitoring tasks, we aggregate by hour or minute.\n",
    "If ts is \"YYYY-MM-DD HH:MM:SS\", then:\n",
    "\n",
    "hour_key = ts[:13]  # 'YYYY-MM-DD HH'\n",
    "\n",
    "All logs that share the same hour_key go into the same group.\n",
    "\"\"\"\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "def group_logs_by_hour(logs):\n",
    "    groups = defaultdict(list)\n",
    "    for log in logs:\n",
    "        hour = log[\"ts\"][:13]  # '2025-11-20 10'\n",
    "        groups[hour].append(log)\n",
    "    return groups\n",
    "\n",
    "groups = group_logs_by_hour(logs)\n",
    "# Example: groups[\"2025-11-20 10\"] → 2 logs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6427431f-008b-4119-859b-b9f594092985",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Why this is “Group by Hour/Minute”\n",
    "We’re grouping by time buckets, not the exact timestamp. This is standard for throughput, error-rate, and alerting pipelines.\n",
    "\n",
    "**Time & Space Complexity**\n",
    "\n",
    "Time: one pass over logs → O(n)\n",
    "\n",
    "Space: store all logs in hour-buckets → O(n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "638930dd-8fc1-460d-bbef-95c049e43419",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**Pattern 5** — Nested Grouping (Year → Month → Rows)\n",
    "\n",
    "**Problem:** Group events hierarchically by year and then by month.\n",
    "\n",
    "**Task:** Build year → month → list of rows, to later run year-level and month-level aggregations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "709c2faa-6f8e-43ae-b87f-0c18c412706a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "rows = [\n",
    "    {\"year\": 2025, \"month\": 11, \"views\": 100},\n",
    "    {\"year\": 2025, \"month\": 11, \"views\": 200},\n",
    "    {\"year\": 2025, \"month\": 12, \"views\": 150},\n",
    "    {\"year\": 2024, \"month\": 12, \"views\": 90},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "fff9c2b6-6691-4d39-a359-f8d3e37d47ee",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Idea (Nested defaultdicts)\n",
    "\n",
    "We need a 2-level grouping: first by year, then by month.\n",
    "\n",
    "Use:\n",
    "groups = defaultdict(lambda: defaultdict(list))\n",
    "\n",
    "Then for each row:\n",
    "- groups[year][month].append(row)\n",
    "\n",
    "This mirrors a cube: year → month → facts.\n",
    "\"\"\"\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "def nested_group_year_month(rows):\n",
    "    groups = defaultdict(lambda: defaultdict(list))\n",
    "    for r in rows:\n",
    "        y = r[\"year\"]\n",
    "        m = r[\"month\"]\n",
    "        groups[y][m].append(r)\n",
    "    return groups\n",
    "\n",
    "groups = nested_group_year_month(rows)\n",
    "# Example: groups[2025][11] → 2 rows, groups[2025][12] → 1 row\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9815047b-a5b2-437b-bbbc-de62c3040b68",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Why this is “Nested Grouping”\n",
    "Instead of a single dict keyed by a composite tuple, we model the hierarchy explicitly: groups[year][month]. Very similar to partition folders: /year=2025/month=11/.\n",
    "\n",
    "**Time & Space Complexity**\n",
    "\n",
    "Time: one pass over rows → O(n)\n",
    "\n",
    "Space: every row stored once in a nested structure → O(n)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "9.1 Grouping",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
