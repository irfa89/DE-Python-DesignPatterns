{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "706dce5a-b4c3-4ea3-9def-78dc3b29737c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**⭐ 1. What This Pattern Solves**\n",
    "\n",
    "Flattening is used when you have nested columns (structs, arrays, maps) and you want to convert them into a wide table with individual columns.\n",
    "\n",
    "Use cases:\n",
    "\n",
    "Converting JSON or complex Parquet files into tabular format.\n",
    "\n",
    "Preparing nested event logs for analytics or BI tools.\n",
    "\n",
    "Flattening exploded arrays/structs for joins or aggregations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7945b2e1-dccd-4d8d-94d3-6c342e866fd0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**⭐ 2. SQL Equivalent**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "cad5de46-46a2-40ca-9bfe-14c67ba46849",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "-- Flatten struct column\n",
    "SELECT \n",
    "    nested_col.field1 AS field1,\n",
    "    nested_col.field2 AS field2\n",
    "FROM table;\n",
    "\n",
    "-- Flatten array of structs (after explode)\n",
    "SELECT \n",
    "    exploded_col.field1,\n",
    "    exploded_col.field2\n",
    "FROM table\n",
    "LATERAL VIEW explode(array_struct_col) t AS exploded_col;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "fec8cb77-8a63-461a-ad7c-272bf41b7922",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**⭐ 3. Core Idea**\n",
    "\n",
    "Access nested fields using dot notation (struct_col.field) and optionally explode arrays first. Flattening turns nested structures → individual columns for analytics or joins."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "75f768f3-9cfc-4592-a631-2755f1a5f37e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**⭐ 4. Template Code (MEMORIZE THIS)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "08f9cf4a-ae7c-4042-a9f1-9f8e4414efbf",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Flatten struct\n",
    "df.select(\"id\", \"struct_col.field1\", \"struct_col.field2\")\n",
    "\n",
    "# Flatten exploded array of structs\n",
    "from pyspark.sql.functions import explode\n",
    "df.select(\"id\", explode(\"array_col\").alias(\"exploded\")) \\\n",
    "  .select(\"id\", \"exploded.field1\", \"exploded.field2\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b1bebe8d-3530-4f6f-9d0b-9224413eb4da",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**⭐ 5. Detailed Example**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "93a3563f-1bb5-47e3-abc6-e4748bafcaab",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import Row\n",
    "\n",
    "data = [\n",
    "    Row(id=1, info=Row(name=\"Alice\", age=30)),\n",
    "    Row(id=2, info=Row(name=\"Bob\", age=25))\n",
    "]\n",
    "\n",
    "df = spark.createDataFrame(data)\n",
    "df.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6b7a7ed2-9f15-4252-a90e-34ee42235498",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "+---+-----------+\n",
    "|id |info       |\n",
    "+---+-----------+\n",
    "|1  |{Alice,30} |\n",
    "|2  |{Bob,25}   |\n",
    "+---+-----------+"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f0ee48f8-51b2-4901-9252-3980ccf864c4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_flat = df.select(\"id\", \"info.name\", \"info.age\")\n",
    "df_flat.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "918917bc-e7aa-4bc0-8f25-8db5cbebacde",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "+---+-----+---+\n",
    "|id |name |age|\n",
    "+---+-----+---+\n",
    "|1  |Alice|30 |\n",
    "|2  |Bob  |25 |\n",
    "+---+-----+---+"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6258cc49-02a3-4545-b1be-13ad6cdb2417",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import explode\n",
    "\n",
    "data = [(1, [Row(item=\"apple\", qty=5), Row(item=\"banana\", qty=3)])]\n",
    "df2 = spark.createDataFrame(data, [\"id\", \"items\"])\n",
    "\n",
    "df2_flat = df2.select(\"id\", explode(\"items\").alias(\"item\"))\n",
    "df2_flat.select(\"id\", \"item.item\", \"item.qty\").show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "eb783c28-8823-41e2-a62a-8d50682eb4a4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "+---+-----+---+\n",
    "|id |item |qty|\n",
    "+---+-----+---+\n",
    "|1  |apple|5  |\n",
    "|1  |banana|3 |\n",
    "+---+-----+---+"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "11c50ea1-6e9d-44fa-af7a-072a7bc6abff",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**⭐ 6. Mini Practice Problems**\n",
    "\n",
    "Flatten a struct column with nested address (address.street, address.city).\n",
    "\n",
    "Explode and flatten an array of structs representing orders.\n",
    "\n",
    "Flatten a JSON-parsed struct column into multiple columns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "20f011c9-e50d-4ec1-96b9-dc77e1c97b57",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**⭐ 7. Full Data Engineering Problem**\n",
    "\n",
    "You ingest nested JSON logs from S3: each row has user (struct) and events (array of structs).\n",
    "\n",
    "Task: Flatten user → user_id, user_name and explode events → event_type, timestamp for analytics.\n",
    "\n",
    "Pattern: from_json → explode → select nested fields → write to Silver table."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d60f0fe8-2dfa-45fc-8664-c2d3eadd6c4c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**⭐ 8. Time & Space Complexity**\n",
    "\n",
    "Time: O(n * m) if exploding arrays (n rows, m elements per array)\n",
    "\n",
    "Space: Flattening does not increase rows, but exploding arrays multiplies rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ce06429b-c007-42df-b285-cd11b4825d0a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**⭐ 9. Common Pitfalls**\n",
    "\n",
    "Forgetting to alias exploded columns → column name conflicts.\n",
    "\n",
    "Trying to flatten without exploding arrays → still nested.\n",
    "\n",
    "Accessing deeply nested fields incorrectly → struct_col.array_col.field must be correctly chained.\n",
    "\n",
    "Flattening too early → may duplicate rows unnecessarily if joins are required first."
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "4.4 nested data",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
