{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "fbe3dc92-9271-44e1-8d20-94cc7025379d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**⭐ 1. What This Pattern Solves**\n",
    "\n",
    "Streaming aggregations allow you to compute metrics continuously on a stream of data rather than batch.\n",
    "Use-cases include:\n",
    "\n",
    "Real-time sales per product\n",
    "\n",
    "Active users per minute/hour\n",
    "\n",
    "Error counts from logs in real-time\n",
    "\n",
    "The main challenge is maintaining aggregates efficiently over unbounded streams."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e28dfc23-156e-417d-afe3-ae3e13797306",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**⭐ 2. SQL Equivalent**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "48623b9a-3b3f-493c-a1a6-31581967e294",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "SELECT product_id, SUM(sales_amount) AS total_sales, window(event_time, '1 hour') AS hour_window\n",
    "FROM sales_stream\n",
    "GROUP BY product_id, window(event_time, '1 hour')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "759b2fbb-2c46-4228-998c-8ced6390e647",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**⭐ 3. Core Idea**\n",
    "\n",
    "Use structured streaming with groupBy on keys + window\n",
    "\n",
    "Aggregations are incremental; only changes since last trigger are processed\n",
    "\n",
    "Works with event-time windows for time-based metrics\n",
    "\n",
    "Supports watermarks to handle late data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "84a907eb-5101-4636-94be-a3330c47f019",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**⭐ 4. Template Code (MEMORIZE THIS)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "821c02c5-7fed-4245-9500-06bf9184ec97",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import window, sum as Fsum\n",
    "\n",
    "streaming_df.groupBy(\n",
    "    \"key_col\",\n",
    "    window(\"event_time\", \"window_duration\")\n",
    ").agg(\n",
    "    Fsum(\"metric_col\").alias(\"agg_metric\")\n",
    ")\n",
    ".writeStream \\\n",
    "    .outputMode(\"update\") \\\n",
    "    .format(\"console\") \\\n",
    "    .start()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0b6797b7-f10d-4678-91df-90316e0a26ee",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**⭐ 5. Detailed Example**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ab441731-e9a7-4da6-9489-f6fd58ed4485",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import window, sum as Fsum\n",
    "import pyspark.sql.types as T\n",
    "\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "\n",
    "# Simulate streaming source\n",
    "schema = T.StructType([\n",
    "    T.StructField(\"product_id\", T.StringType()),\n",
    "    T.StructField(\"sales_amount\", T.IntegerType()),\n",
    "    T.StructField(\"event_time\", T.TimestampType())\n",
    "])\n",
    "\n",
    "streaming_df = spark.readStream.schema(schema).json(\"/tmp/sales_stream\")\n",
    "\n",
    "agg_df = streaming_df.groupBy(\n",
    "    \"product_id\",\n",
    "    window(\"event_time\", \"1 hour\")\n",
    ").agg(\n",
    "    Fsum(\"sales_amount\").alias(\"total_sales\")\n",
    ")\n",
    "\n",
    "query = agg_df.writeStream.outputMode(\"update\").format(\"console\").start()\n",
    "query.awaitTermination()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "923bcef2-edaf-481d-bfc8-0192b741e05a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**Step-by-step:**\n",
    "\n",
    "Read stream and define schema\n",
    "\n",
    "Group by key and event-time window\n",
    "\n",
    "Aggregate metric incrementally\n",
    "\n",
    "Output continuously"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9605e04e-bf11-42b9-b6b9-eaf6c5fb0966",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**⭐ 6. Mini Practice Problems**\n",
    "\n",
    "Count user logins per 5-minute window.\n",
    "\n",
    "Compute average order value per 1-hour window.\n",
    "\n",
    "Find top 3 products per 30-minute window in a streaming source."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0364a4a6-82c0-4a15-9a9b-cc84d5ef4cd9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**⭐ 7. Full Data Engineering Problem**\n",
    "\n",
    "Scenario: E-commerce platform needs real-time dashboard of sales per product per hour. Data arrives via Kafka (millions of events/day).\n",
    "\n",
    "Solution Approach:\n",
    "\n",
    "Stream data from Kafka\n",
    "\n",
    "Assign event time and watermark\n",
    "\n",
    "Aggregate using groupBy + window\n",
    "\n",
    "Write to Delta table or dashboard\n",
    "\n",
    "Optimize: watermarking, stateful aggregation, trigger intervals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "86985221-6617-4589-9d24-0fbbd1f7b3e4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**⭐ 8. Time & Space Complexity**\n",
    "\n",
    "Time: O(N) per micro-batch, dependent on aggregation keys and window size\n",
    "\n",
    "Space: O(unique keys × window state)\n",
    "\n",
    "Large key cardinality → consider state cleanup & watermarks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "35ab893d-7968-468f-bc9d-061bed2e5a75",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**⭐ 9. Common Pitfalls**\n",
    "\n",
    "Forgetting to use watermark → state grows unbounded\n",
    "\n",
    "Using append mode with non-time windows → results missing\n",
    "\n",
    "Large window + high cardinality → memory overflow\n",
    "\n",
    "Incorrect event-time assignment → late events ignored"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "8.4 streaming aggregates",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
