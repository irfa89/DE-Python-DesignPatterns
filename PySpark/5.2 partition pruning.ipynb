{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d30cc3d8-f146-4fa6-9576-fe0c997af5c8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**⭐ 1. What This Pattern Solves**\n",
    "\n",
    "Reduces I/O and shuffle by scanning only relevant partitions in a partitioned table.\n",
    "\n",
    "Critical for large datasets in Delta, Parquet, or Hive.\n",
    "\n",
    "Improves query performance by avoiding full table scans.\n",
    "\n",
    "Use cases:\n",
    "\n",
    "Filtering large historical logs by date.\n",
    "\n",
    "Querying customer data in a partitioned table by region or country.\n",
    "\n",
    "Optimizing ETL pipelines by limiting input size."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e28c43f5-3031-407e-8576-def9e6f08ab7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**⭐ 2. SQL Equivalent**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f046c733-c172-4178-ba40-46d31b5dfcdb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "-- Table partitioned by date\n",
    "SELECT *\n",
    "FROM sales\n",
    "WHERE sale_date = '2025-12-01';  -- Only relevant partition scanned\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f23df4cf-0d1b-4d5a-bbbb-3f49baa52f46",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**⭐ 3. Core Idea**\n",
    "\n",
    "Partition pruning works when filters match partition columns.\n",
    "\n",
    "Spark can skip irrelevant partitions → less read → faster execution.\n",
    "\n",
    "Combine with pushdown filters for maximum efficiency."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "98889eef-85b8-4270-9229-4aa921949873",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**⭐ 4. Template Code (MEMORIZE THIS)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "054c0011-33b2-4840-b653-349efb7b823b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Read partitioned table with filter on partition column\n",
    "df = spark.read.parquet(\"path/to/partitioned_data\") \\\n",
    "       .filter(\"partition_col = 'value'\")\n",
    "\n",
    "# OR using .where()\n",
    "df = spark.read.parquet(\"path/to/partitioned_data\") \\\n",
    "       .where(df.partition_col == \"value\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "07a5a76b-9833-4d83-96f7-2baf68af680b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**⭐ 5. Detailed Example**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ee3726d2-1536-4cfd-887e-dc99c17e7402",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "data = [\n",
    "    (\"2025-12-01\", \"Alice\", 100),\n",
    "    (\"2025-12-02\", \"Bob\", 200),\n",
    "    (\"2025-12-01\", \"Charlie\", 300)\n",
    "]\n",
    "df = spark.createDataFrame(data, [\"date\", \"name\", \"amount\"])\n",
    "\n",
    "# Write partitioned by date\n",
    "df.write.partitionBy(\"date\").mode(\"overwrite\").parquet(\"s3://data/sales\")\n",
    "\n",
    "# Read only 2025-12-01 partition\n",
    "df_filtered = spark.read.parquet(\"s3://data/sales\").filter(\"date = '2025-12-01'\")\n",
    "df_filtered.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "53b45498-c92d-446b-a528-7d4123c19d17",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**⭐ 6. Mini Practice Problems**\n",
    "\n",
    "Read a Delta table partitioned by region and filter only region='US'.\n",
    "\n",
    "Why does filtering a non-partitioned column not benefit from partition pruning?\n",
    "\n",
    "Write a DataFrame partitioned by year and month, then read only year=2025."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a2feaf16-a907-482f-8971-8297c22dc56b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**⭐ 7. Full Data Engineering Problem**\n",
    "\n",
    "Scenario: You have a 2TB Delta table partitioned by year/month/day. You need yesterday’s logs for aggregation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "444634a7-0b38-4caf-8e59-a1f4d8aaac8e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "yesterday = (datetime.now() - timedelta(days=1)).strftime(\"%Y-%m-%d\")\n",
    "year, month, day = yesterday.split(\"-\")\n",
    "\n",
    "df_yesterday = spark.read.format(\"delta\") \\\n",
    "    .load(\"s3://bronze/logs/\") \\\n",
    "    .filter(f\"year={year} AND month={month} AND day={day}\")\n",
    "\n",
    "# Aggregate user clicks\n",
    "agg_df = df_yesterday.groupBy(\"user_id\").count()\n",
    "agg_df.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7b0edc14-e5ac-419a-96ba-78510cc7f656",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**⭐ 8. Time & Space Complexity**\n",
    "\n",
    "| Operation         | Time Complexity                 | Space Complexity    |\n",
    "| ----------------- | ------------------------------- | ------------------- |\n",
    "| Partition pruning | O(n/p) (scan only p partitions) | O(filtered records) |\n",
    "| Full table scan   | O(n)                            | O(n)                |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "beaf52eb-e023-4b1a-9197-38af0148defc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**⭐ 9. Common Pitfalls**\n",
    "\n",
    "Filtering non-partitioned columns → no pruning.\n",
    "\n",
    "Using complex expressions on partition columns → Spark may not prune.\n",
    "\n",
    "Forgetting to partition at write time → cannot prune later.\n",
    "\n",
    "Over-partitioning → too many small files → overhead > benefit."
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "5.2 partition pruning",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
