{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ee21f874-6394-4009-825d-cfba2c0e71f0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**⭐ 1. What This Pattern Solves**\n",
    "\n",
    "Guides Spark’s query planner to make better optimization decisions:\n",
    "\n",
    "Broadcast hints → force small table to be broadcasted to all nodes, avoiding shuffle in joins.\n",
    "\n",
    "Merge hints → optimize Delta table merge operations for performance.\n",
    "\n",
    "Use cases:\n",
    "\n",
    "Joining a huge fact table with a small dimension table.\n",
    "\n",
    "Performing incremental updates with MERGE INTO on Delta tables.\n",
    "\n",
    "Reducing shuffle in large joins or merges."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2dd8f65f-dc7b-4feb-959f-ffad5b301a3e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**⭐ 2. SQL Equivalent**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "23bf936f-dc8c-4f45-9e0a-3c9ab3b2ff98",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "-- Broadcast hint\n",
    "SELECT /*+ BROADCAST(small_table) */ *\n",
    "FROM big_table b\n",
    "JOIN small_table s\n",
    "ON b.id = s.id;\n",
    "\n",
    "-- Merge hint (Delta)\n",
    "MERGE INTO target t\n",
    "USING source s\n",
    "ON t.id = s.id\n",
    "WHEN MATCHED THEN UPDATE SET t.value = s.value\n",
    "WHEN NOT MATCHED THEN INSERT *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "05c3963e-8778-42ee-8cce-c312816128e8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**The broadcast hint avoids full shuffle.**\n",
    "\n",
    "Delta merge automatically handles updates/inserts efficiently."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a88fec74-d0c3-488b-b60e-e34cef543fe4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**⭐ 3. Core Idea**\n",
    "\n",
    "Spark’s optimizer decides whether to shuffle or broadcast; hints override the default.\n",
    "\n",
    "Use broadcast when the small table fits in memory.\n",
    "\n",
    "Use merge for upserts in Delta → efficient, avoids full overwrite."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e8f13a9a-70ce-4173-8347-c01a568e5978",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**⭐ 4. Template Code (MEMORIZE THIS)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9190b13f-acab-44b2-a95f-0051f69f7030",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import broadcast\n",
    "\n",
    "# Broadcast small DF in join\n",
    "df_joined = large_df.join(broadcast(small_df), \"id\")\n",
    "\n",
    "# Delta Merge\n",
    "from delta.tables import DeltaTable\n",
    "delta_table = DeltaTable.forPath(spark, \"/mnt/delta/target\")\n",
    "delta_table.alias(\"t\").merge(\n",
    "    source=source_df.alias(\"s\"),\n",
    "    condition=\"t.id = s.id\"\n",
    ").whenMatchedUpdateAll() \\\n",
    " .whenNotMatchedInsertAll() \\\n",
    " .execute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7247d2cc-240f-483a-b780-48eb9af3d0fe",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**⭐ 5. Detailed Example**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0e0a0452-6f3a-4bf0-837b-a7e1a623e87b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import broadcast\n",
    "from delta.tables import DeltaTable\n",
    "\n",
    "spark = SparkSession.builder.appName(\"PerfPatterns\").getOrCreate()\n",
    "\n",
    "# Example DataFrames\n",
    "large_data = [(i, i*2) for i in range(1000000)]\n",
    "small_data = [(i, \"NY\") for i in range(1000)]\n",
    "large_df = spark.createDataFrame(large_data, [\"id\", \"value\"])\n",
    "small_df = spark.createDataFrame(small_data, [\"id\", \"state\"])\n",
    "\n",
    "# Broadcast join\n",
    "joined_df = large_df.join(broadcast(small_df), \"id\")\n",
    "joined_df.show()\n",
    "\n",
    "# Delta merge example\n",
    "delta_table = DeltaTable.forPath(spark, \"/mnt/delta/customers\")\n",
    "source_df = spark.createDataFrame([(1, \"Alice_new\")], [\"id\", \"name\"])\n",
    "delta_table.alias(\"t\").merge(\n",
    "    source=source_df.alias(\"s\"),\n",
    "    condition=\"t.id = s.id\"\n",
    ").whenMatchedUpdateAll() \\\n",
    " .whenNotMatchedInsertAll() \\\n",
    " .execute()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "46bc4d51-4770-4cdd-9c91-f0885ec2dece",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**Explanation:**\n",
    "\n",
    "broadcast(small_df) → avoids shuffle.\n",
    "\n",
    "merge → safely updates/inserts data into Delta table efficiently."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7893c527-b5fa-433b-987c-c573e88b8c5d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**⭐ 6. Mini Practice Problems**\n",
    "\n",
    "When would you use a broadcast hint in a join?\n",
    "\n",
    "Write a Delta merge to update a record if it exists and insert if it doesn’t.\n",
    "\n",
    "Why is broadcasting too large a table dangerous?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2df28621-cdcb-4293-b449-fc573b30689f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**⭐ 7. Full Data Engineering Problem**\n",
    "\n",
    "Scenario: You have a 1TB sales fact table and a 10K customer dimension table. You need to update customer info in a Delta table efficiently while joining for analytics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7e6bafc0-fb3f-45f2-8b2b-9c1f6568d95a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import broadcast\n",
    "from delta.tables import DeltaTable\n",
    "\n",
    "# Broadcast join for analytics\n",
    "df_analytics = sales.join(broadcast(customers), \"customer_id\")\n",
    "\n",
    "# Delta merge for updates\n",
    "delta_customers = DeltaTable.forPath(spark, \"/mnt/delta/customers\")\n",
    "delta_customers.alias(\"t\").merge(\n",
    "    source=updates.alias(\"s\"),\n",
    "    condition=\"t.customer_id = s.customer_id\"\n",
    ").whenMatchedUpdateAll() \\\n",
    " .whenNotMatchedInsertAll() \\\n",
    " .execute()\n",
    "\n",
    " # Minimizes shuffle, supports safe upserts, efficient for large-scale pipelines."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "964c9d44-815e-4743-acfe-2cc92507bfd1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**⭐ 8. Time & Space Complexity**\n",
    "\n",
    "| Operation      | Time Complexity                                           | Space Complexity            |\n",
    "| -------------- | --------------------------------------------------------- | --------------------------- |\n",
    "| Broadcast join | O(n) scan large table, O(small_table_size * nodes) memory | O(small_table) per executor |\n",
    "| Delta merge    | O(n) + O(m) shuffle if needed                             | O(n+m) on disk              |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "cccfc41b-8f98-446c-97bd-46bc181f891c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**⭐ 9. Common Pitfalls**\n",
    "\n",
    "Broadcasting too large tables → executor OOM.\n",
    "\n",
    "Forgetting to alias tables in merge → Spark Delta error.\n",
    "\n",
    "Using merge on huge tables without filtering → full scan → slow.\n",
    "\n",
    "Ignoring shuffle reduction → performance suffers despite hints."
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "5.6 hints",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
