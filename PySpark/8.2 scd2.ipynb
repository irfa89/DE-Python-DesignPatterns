{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c88340fa-ecf0-42f6-b48b-eb0bef54d856",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**⭐ 1. What This Pattern Solves**\n",
    "\n",
    "SCD Type 2 handles historical changes in dimension data while keeping history intact.\n",
    "Use-cases include:\n",
    "\n",
    "Customer changes address → keep old and new records\n",
    "\n",
    "Product price changes → track price history\n",
    "\n",
    "Employee department changes → preserve historical assignments\n",
    "\n",
    "Goal: maintain a full history for analytics while marking the current record."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "56e3cfef-0873-4a09-9abc-0cc4cc98bcb9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**⭐ 2. SQL Equivalent**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6f269ca3-9ec5-42a6-b031-5a42438e47b3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "MERGE INTO dim_customer AS target\n",
    "USING staging_customer AS source\n",
    "ON target.customer_id = source.customer_id\n",
    "WHEN MATCHED AND target.name != source.name THEN\n",
    "    UPDATE SET target.end_date = CURRENT_DATE\n",
    "WHEN NOT MATCHED THEN\n",
    "    INSERT (customer_id, name, start_date, end_date, is_current)\n",
    "    VALUES (source.customer_id, source.name, CURRENT_DATE, NULL, TRUE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "383dd742-1c5b-485a-9f2d-5c05c98cc858",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**⭐ 3. Core Idea**\n",
    "\n",
    "Compare incoming data with existing dimension\n",
    "\n",
    "If a change is detected, “expire” old row (end_date)\n",
    "\n",
    "Insert a new row with updated data and is_current=True\n",
    "\n",
    "Use merge or upsert operations (Delta Lake ideal for this)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0149e225-e74f-48f7-bfc5-649a48e87246",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**⭐ 4. Template Code (MEMORIZE THIS)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3218e8bd-c9f6-4702-a5b4-88ee3b36bd36",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from delta.tables import DeltaTable\n",
    "from pyspark.sql.functions import current_date, lit, col\n",
    "\n",
    "delta_table = DeltaTable.forPath(spark, \"path/to/dim_table\")\n",
    "\n",
    "delta_table.alias(\"target\").merge(\n",
    "    source_df.alias(\"source\"),\n",
    "    \"target.id = source.id\"\n",
    ").whenMatchedUpdate(\n",
    "    condition = \"target.attribute <> source.attribute\",\n",
    "    set = {\n",
    "        \"end_date\": current_date(),\n",
    "        \"is_current\": lit(False)\n",
    "    }\n",
    ").whenNotMatchedInsert(\n",
    "    values = {\n",
    "        \"id\": col(\"source.id\"),\n",
    "        \"attribute\": col(\"source.attribute\"),\n",
    "        \"start_date\": current_date(),\n",
    "        \"end_date\": None,\n",
    "        \"is_current\": lit(True)\n",
    "    }\n",
    ").execute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1a2bd906-9c3c-4db9-95d4-2f05b1efec15",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**⭐ 5. Detailed Example**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4b38945f-8411-4b79-b1be-6de7ebbf23bb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from delta.tables import DeltaTable\n",
    "from pyspark.sql.functions import current_date, lit, col\n",
    "\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "\n",
    "# Existing dimension table (Delta)\n",
    "data = [(\"C1\", \"Alice\", \"2025-01-01\", None, True)]\n",
    "dim_df = spark.createDataFrame(data, [\"id\", \"name\", \"start_date\", \"end_date\", \"is_current\"])\n",
    "dim_df.write.format(\"delta\").mode(\"overwrite\").save(\"/tmp/dim_customer\")\n",
    "\n",
    "# Incoming new data\n",
    "new_data = [(\"C1\", \"Alice B\")]\n",
    "source_df = spark.createDataFrame(new_data, [\"id\", \"name\"])\n",
    "\n",
    "# Merge for SCD Type 2\n",
    "delta_table = DeltaTable.forPath(spark, \"/tmp/dim_customer\")\n",
    "delta_table.alias(\"target\").merge(\n",
    "    source_df.alias(\"source\"),\n",
    "    \"target.id = source.id\"\n",
    ").whenMatchedUpdate(\n",
    "    condition = \"target.name <> source.name\",\n",
    "    set = {\n",
    "        \"end_date\": current_date(),\n",
    "        \"is_current\": lit(False)\n",
    "    }\n",
    ").whenNotMatchedInsert(\n",
    "    values = {\n",
    "        \"id\": col(\"source.id\"),\n",
    "        \"name\": col(\"source.name\"),\n",
    "        \"start_date\": current_date(),\n",
    "        \"end_date\": None,\n",
    "        \"is_current\": lit(True)\n",
    "    }\n",
    ").execute()\n",
    "\n",
    "delta_table.toDF().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3cae606d-8022-44a4-a5d4-32fcafa73018",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**Step-by-step:**\n",
    "\n",
    "Compare existing rows with incoming updates\n",
    "\n",
    "Expire old rows if there’s a change (end_date + is_current=False)\n",
    "\n",
    "Insert new rows as current"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7c140152-ad01-407c-a151-b5245f083e7b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**⭐ 6. Mini Practice Problems**\n",
    "\n",
    "Track changes in employee_title for SCD Type 2.\n",
    "\n",
    "Handle price updates for products in a dimension table.\n",
    "\n",
    "Implement SCD Type 2 on a small customer dataset with multiple attribute changes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e2365b6f-efda-4364-8cfb-7fda6fd43a72",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**⭐ 7. Full Data Engineering Problem**\n",
    "\n",
    "Scenario: Daily ETL ingest of customer updates. Customers may change addresses, emails, or status. The analytics team requires full history.\n",
    "\n",
    "Solution Approach:\n",
    "\n",
    "Read staging customer updates\n",
    "\n",
    "Load existing dimension from Delta\n",
    "\n",
    "Use merge with SCD Type 2 logic\n",
    "\n",
    "Write back to Delta with current/expired rows\n",
    "\n",
    "Optimize with Delta ZORDER on frequently queried columns (e.g., customer_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "568364f3-e811-4a2b-acb5-dc455a90b163",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**⭐ 8. Time & Space Complexity**\n",
    "\n",
    "Time: O(N) for merge per batch; can be costly for large tables if partitioning is not used\n",
    "\n",
    "Space: O(N) for storing new rows + metadata\n",
    "\n",
    "Partitioning by key reduces shuffle overhead"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "693e0165-3ae0-4336-a5df-f864ca388eb7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**⭐ 9. Common Pitfalls**\n",
    "\n",
    "Forgetting to mark old row as is_current=False\n",
    "\n",
    "Not updating end_date → analytics will see duplicate current rows\n",
    "\n",
    "Missing partitioning → slow merge and high shuffle\n",
    "\n",
    "Using SCD Type 1 logic by mistake → overwrites history"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "8.2 scd2",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
