{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "187f74a6-7b05-49ca-a05b-58364a7daa01",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**⭐ 1. What This Pattern Solves**\n",
    "\n",
    "Allows you to write SQL directly inside PySpark transformations.\n",
    "\n",
    "Use this pattern when:\n",
    "\n",
    "SQL version is easier than Column API\n",
    "\n",
    "You want complex expressions in one line\n",
    "\n",
    "Migrating SQL logic → PySpark\n",
    "\n",
    "You need functions not easily accessible via F.*\n",
    "\n",
    "Working with window functions inside transformations\n",
    "\n",
    "This pattern is essential for SQL-first data engineers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "37141a4f-324e-445d-8860-5b66cdc7ad5a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**⭐ 2. SQL Equivalent**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a0d7311f-579b-4a39-8573-99469cc31ca7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "SELECT \n",
    "    id,\n",
    "    salary * 1.1 AS bonus,\n",
    "    CONCAT(first_name, ' ', last_name) AS full_name\n",
    "FROM employees;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ac3daf0a-7c5e-4cc3-b3cb-bde501ec1d37",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df.selectExpr(\n",
    "    \"id\",\n",
    "    \"salary * 1.1 AS bonus\",\n",
    "    \"CONCAT(first_name, ' ', last_name) AS full_name\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "91dadf1f-7ed5-4506-ba56-43e028a08734",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df.withColumn(\"bonus\", F.expr(\"salary * 1.1\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "77ff19db-7bcc-4e3e-a0f2-eb6cb5dcbe56",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**⭐ 3. Core Idea**\n",
    "\n",
    "expr() lets you put SQL functions inside PySpark:\n",
    "\n",
    "Math expressions\n",
    "\n",
    "String expressions\n",
    "\n",
    "Date expressions\n",
    "\n",
    "CASE WHEN logic\n",
    "\n",
    "Built-in SQL functions\n",
    "\n",
    "Window expressions (inside selectExpr)\n",
    "\n",
    "You write SQL, Spark compiles it to the Catalyst plan."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5ef3bbcd-3096-45c5-a03a-6bb54340b59f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**⭐ 4. Template Code (MEMORIZE THIS)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3aee6155-c653-46fc-ad1c-4dcac56d5097",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "## Pattern A — Inside withColumn()\n",
    "\n",
    "df.withColumn(\"new_col\", F.expr(\"sql_expression_here\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b97d8364-b523-49b7-b63b-0691dcbb57df",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "## Pattern B — Using selectExpr()\n",
    "\n",
    "df.selectExpr(\n",
    "    \"col1\",\n",
    "    \"sql_expression AS new_col\",\n",
    "    \"CASE WHEN ... END AS flag\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c5cfe9e8-561a-470d-8855-0580f74c401e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**⭐ 5. Detailed Example**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "738d761e-c82c-4a5f-b497-32e969fd4270",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "+----+----------+-----------+\n",
    "| id | first    | last      |\n",
    "+----+----------+-----------+\n",
    "| 1  | Alice    | Smith     |\n",
    "| 2  | Bob      | Johnson   |\n",
    "+----+----------+-----------+\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e3253f78-c868-491e-b95a-2f1db69dd3a7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "\n",
    "out = df.withColumn(\n",
    "    \"full_name\",\n",
    "    F.expr(\"CONCAT(first, ' ', last)\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1f6b6087-2a79-416e-a61b-d9f7e594e95b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "+----+----------+-----------+-----------+\n",
    "| id | first    | last      | full_name |\n",
    "+----+----------+-----------+-----------+\n",
    "| 1  | Alice    | Smith     | Alice Smith|\n",
    "| 2  | Bob      | Johnson   | Bob Johnson|\n",
    "+----+----------+-----------+-----------+\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3710cac1-1f57-421e-897c-04daf8e0a51f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**⭐ 6. Mini Practice Problems (Active Recall)**\n",
    "\n",
    "Create column total = price * quantity using expr().\n",
    "\n",
    "Extract the year from order_date using SQL syntax.\n",
    "\n",
    "Build full_address with \"CONCAT(street, ', ', city, ', ', state)\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "421093bf-ddad-45b1-91f2-9f6559f2cfad",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**⭐ 7. Full Data Engineering Problem**\n",
    "\n",
    "**Scenario:**\n",
    "You have a Bronze Sales table.\n",
    "You must create the Silver enriched version using SQL-style expressions:\n",
    "\n",
    "gross_amount = unit_price * qty\n",
    "\n",
    "net_amount = unit_price * qty * (1 - discount)\n",
    "\n",
    "order_year from order_timestamp\n",
    "\n",
    "is_weekend using SQL CASE WHEN + dayofweek(order_timestamp)\n",
    "\n",
    "**Task:**\n",
    "Write the full PySpark transformation using ONLY expr() or selectExpr().\n",
    "\n",
    "This mirrors enterprise sales pipelines in retail, travel, and e-commerce."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2c904212-5742-47d1-875f-f1aff301639e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**⭐ 8. Time & Space Complexity**\n",
    "\n",
    "| Operation           | Complexity                       |\n",
    "| ------------------- | -------------------------------- |\n",
    "| `expr()` evaluation | **O(n)** — computes for each row |\n",
    "| Memory              | Depends on number of new columns |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e71c7e84-24cd-45e1-9e72-ac604650a82d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**⭐ 9. Common Pitfalls**\n",
    "\n",
    "❌ Using Python string ops instead of SQL ops\n",
    "❌ Forgetting you can use CASE WHEN inside expr()\n",
    "❌ Mixing SQL syntax with Column syntax incorrectly\n",
    "❌ Hardcoding strings without quotes inside expression\n",
    "❌ Misusing selectExpr(\"*\", \"...\") without alias → duplicate col names"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "1.5 expressions",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
