{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "254d9d1e-d734-4572-aa31-7884437b22c5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**⭐ 1. What This Pattern Solves**\n",
    "\n",
    "Mitigate performance degradation when join key is skewed (a few keys hold most rows) causing single task hotspots and long straggling tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "264fb7d4-0c73-4e08-8ed8-dd62d78b64f2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**⭐ 2. SQL Equivalent**\n",
    "\n",
    "No single SQL hint; implemented via data transformation techniques (salting, splitting large-key joins)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e1f179b8-b9cb-46cc-94ba-b2745c67b66c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**⭐ 3. Core Idea**\n",
    "\n",
    "Split the join into (a) handle heavy keys separately, and (b) salt keys to spread load across partitions (add random suffix to join key), or use map-side aggregation and replicate small side selectively. Main approaches: salting, range/bucket join, skewed-key special-case."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "de0232f1-e479-4f14-a3a2-fba97e076a54",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**⭐ 4. Template Code (MEMORIZE THIS) — SALTING**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3628b49d-605b-4331-8f70-a244c9f0ade6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "import random\n",
    "\n",
    "# 1. mark heavy keys (example list heavy_keys)\n",
    "heavy_keys = [...]  # discovered from stats\n",
    "\n",
    "# 2. For left: add salt for heavy keys\n",
    "salt_count = 10\n",
    "left_salted = left.withColumn('salt', F.when(F.col('key').isin(heavy_keys),\n",
    "                                             (F.rand()*salt_count).cast('int'))\n",
    "                                           .otherwise(F.lit(0)))\n",
    "left_salted = left_salted.withColumn('salted_key', F.concat_ws('_', F.col('key'), F.col('salt')))\n",
    "\n",
    "# 3. For right: replicate heavy keys with salts 0..salt_count-1\n",
    "right_heavy = right.filter(F.col('key').isin(heavy_keys))\n",
    "replicated = (right_heavy\n",
    "              .withColumn('salt', F.explode(F.array([F.lit(i) for i in range(salt_count)])))\n",
    "              .withColumn('salted_key', F.concat_ws('_', F.col('key'), F.col('salt'))))\n",
    "# 4. non-heavy keys join normally (salt=0)\n",
    "right_rest = right.filter(~F.col('key').isin(heavy_keys)).withColumn('salt', F.lit(0)).withColumn('salted_key', F.concat_ws('_', F.col('key'), F.col('salt')))\n",
    "\n",
    "right_salted = replicated.unionByName(right_rest)\n",
    "joined = left_salted.join(right_salted, on='salted_key', how='inner')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e7fa4810-1fdf-4555-a898-ba3e74ae1bcb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**⭐ 5. Detailed Example**\n",
    "\n",
    "Discover skew: left.groupBy('key').count().orderBy(F.desc('count')).show(10) → find keys with huge counts.\n",
    "\n",
    "Choose salt_count (e.g., 8–32).\n",
    "\n",
    "Add salt to left only for heavy keys; replicate right heavy keys by exploding salts so every partition holds a slice.\n",
    "\n",
    "Join on salted_key. This spreads heavy key workload across many tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6a25e006-fdf6-4304-845d-59a4b0d8b4c9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**⭐ 7. Full Data Engineering Problem**\n",
    "\n",
    "You run daily enrichment: clicks (large, highly skewed by ip_country='US') join dim_country (small). US dominates 70% rows causing stragglers. Implement skew mitigation: for US create salts on clicks, replicate dim_country for US with salts, join on salted key, then remove salt. Provide metrics to prove reduced max task time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "48c53827-1662-4eff-a95b-b19ce7449e08",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**⭐ 8. Time & Space Complexity**\n",
    "\n",
    "Extra cost from replication: right heavy keys replicated salt_count times → increases overall data size. But max task time reduces roughly by factor salt_count. Tradeoff: extra IO for replication vs parallelism gain."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9e00174a-8bcc-41c5-a899-2dc4c8cd82f6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**⭐ 9. Common Pitfalls**\n",
    "\n",
    "Choosing too high salt_count → overhead outweighs benefit.\n",
    "\n",
    "Forgetting to replicate right-side heavy keys with same salt values.\n",
    "\n",
    "Not removing the salt column afterwards (pollutes downstream).\n",
    "\n",
    "Overlooking alternative fixes: filtering heavy keys and joining separately, or rethinking schema."
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "2.6 skew join",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
