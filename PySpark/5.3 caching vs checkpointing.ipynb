{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7d4f9315-bca1-43fc-b4e3-b3a89ce8be4c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "⭐ 1. What This Pattern Solves\n",
    "\n",
    "Optimizes iterative and long lineage computations in Spark.\n",
    "\n",
    "Caching: keeps intermediate DataFrames in memory for repeated access → avoids recomputation.\n",
    "\n",
    "Checkpointing: truncates lineage and saves DataFrame to reliable storage (HDFS/S3/DBFS) → avoids very long DAGs that can fail.\n",
    "\n",
    "Use cases:\n",
    "\n",
    "Machine learning pipelines with multiple passes over the same data.\n",
    "\n",
    "Iterative transformations on large DataFrames.\n",
    "\n",
    "Preventing stack overflow / long lineage errors in long ETL DAGs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "bd96d119-77ef-4ebf-9b54-765bb37cf9fc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**⭐ 2. SQL Equivalent**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ed68e3a2-3c17-416c-94b2-03afce4efd9c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "-- Cache in Spark is like using a temp table\n",
    "CREATE TEMP VIEW temp AS\n",
    "SELECT * FROM big_table;\n",
    "-- Reuse temp view multiple times without re-scanning the source\n",
    "\n",
    "-- Checkpointing is similar to persisting intermediate results\n",
    "CREATE TABLE checkpointed AS\n",
    "SELECT * FROM big_table;\n",
    "-- Use this table as a new starting point"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "40b73189-c375-4187-805e-e4047aca85cd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**⭐ 3. Core Idea**\n",
    "\n",
    "Cache → keep in memory, fast, volatile.\n",
    "\n",
    "Checkpoint → write to reliable storage, truncates lineage, useful for recovery.\n",
    "\n",
    "Use cache for speed; checkpoint for stability in long pipelines."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3c948f4e-3f1a-4e65-8c0d-9ed72fda9362",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**⭐ 4. Template Code (MEMORIZE THIS)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0c57afd9-df3e-43d8-9083-ce035e77018c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Caching in memory\n",
    "df_cached = df.cache()   # also df.persist(StorageLevel.MEMORY_ONLY)\n",
    "\n",
    "# Checkpointing to storage\n",
    "spark.sparkContext.setCheckpointDir(\"/checkpoint/path\")\n",
    "df_checkpointed = df.checkpoint()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a2e0fece-ccb8-49bd-a71a-24aa415833ac",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**⭐ 5. Detailed Example**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8047d3ac-47ee-4bcc-8fdd-3ec2c677ad37",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName(\"PerfPatterns\").getOrCreate()\n",
    "\n",
    "data = [(i, i*2) for i in range(1000)]\n",
    "df = spark.createDataFrame(data, [\"id\", \"value\"])\n",
    "\n",
    "# Cache: repeated use\n",
    "df_cached = df.filter(\"value % 2 = 0\").cache()\n",
    "df_cached.count()  # triggers caching\n",
    "df_cached.show()   # uses cache\n",
    "\n",
    "# Checkpoint: long lineage protection\n",
    "spark.sparkContext.setCheckpointDir(\"/tmp/checkpoint\")\n",
    "df_long = df_cached.withColumn(\"double_value\", df_cached.value*2)\n",
    "df_checkpointed = df_long.checkpoint()\n",
    "df_checkpointed.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "136fbb24-9a9c-4226-bf2a-53e38aaa307b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**Explanation:**\n",
    "\n",
    ".cache() → keeps df_cached in memory after first action.\n",
    "\n",
    ".checkpoint() → materializes df_long to disk, truncates lineage, safer for long ETL DAGs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9e21934a-b236-4141-ba37-4b2378eb036f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**⭐ 7. Full Data Engineering Problem**\n",
    "\n",
    "Scenario: You have a 500GB customer transaction dataset. Your ETL pipeline:\n",
    "\n",
    "Filters by country\n",
    "\n",
    "Aggregates by month\n",
    "\n",
    "Joins with reference data\n",
    "\n",
    "Writes to Delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1112b03e-c5a9-400c-a31c-544848890145",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_filtered = df.filter(\"country = 'US'\").cache()  # step 1, repeated multiple joins\n",
    "agg_df = df_filtered.groupBy(\"month\").sum(\"amount\")\n",
    "spark.sparkContext.setCheckpointDir(\"/mnt/checkpoint\")\n",
    "agg_checkpointed = agg_df.checkpoint()  # protect long lineage\n",
    "agg_checkpointed.write.format(\"delta\").mode(\"overwrite\").save(\"/mnt/silver/agg\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "09491eb7-bde5-4d94-9051-fd819662ea29",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**⭐ 8. Time & Space Complexity**\n",
    "\n",
    "| Operation    | Time Complexity                    | Space Complexity |\n",
    "| ------------ | ---------------------------------- | ---------------- |\n",
    "| cache()      | O(n) first action, then O(1) reads | O(n) in memory   |\n",
    "| checkpoint() | O(n) write to storage              | O(n) in disk     |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "dac894ea-20a0-47f0-84db-0659d6e7b9b2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**⭐ 9. Common Pitfalls**\n",
    "\n",
    "Caching too many large DataFrames → memory pressure → OOM.\n",
    "\n",
    "Forgetting to perform an action after .cache() → nothing is cached.\n",
    "\n",
    "Checkpointing without setting checkpoint directory → error.\n",
    "\n",
    "Overusing checkpoint → unnecessary disk I/O."
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "5.3 caching vs checkpointing",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
